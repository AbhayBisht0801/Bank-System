{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\bisht\\\\OneDrive\\\\Desktop\\\\Personal_project\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir:Path\n",
    "    cnn_trained_model_path:Path\n",
    "    updated_base_model_path:Path\n",
    "    training_data:Path\n",
    "    params_epochs:int\n",
    "    params_batch_size:int\n",
    "    params_image_size:list\n",
    "    credit_score_model:Path\n",
    "    transaction_model:Path\n",
    "    params_is_augmentation: bool\n",
    "    transaction_dir:Path\n",
    "    credit_score_dir:Path\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Banking_System.constants import *\n",
    "from src.Banking_System.utils.common import read_yaml,create_directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath=CONFIG_FILE_PATH,\n",
    "            params_filepath=PARAMS_FILE_PATH\n",
    "    ):\n",
    "        self.config=read_yaml(config_filepath)\n",
    "        self.params=read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir,'data\\\\train')\n",
    "        transaction_dir=self.config.data_ingestion.transaction_dir\n",
    "        credit_score_dir=self.config.data_ingestion.credit_score_dir\n",
    "        \n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            cnn_trained_model_path=Path(training.cnn_trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE,\n",
    "            credit_score_model=Path(training.credit_score_model),\n",
    "            transaction_model=Path(training.transaction_model),\n",
    "            credit_score_dir=Path(credit_score_dir),\n",
    "            transaction_dir=Path(transaction_dir)\n",
    "\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pandas as pd\n",
    "from src.Banking_System.utils.common import evaluate_model_transaction,evaluate_model_creditscore,save_object\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from src.Banking_System import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "      \n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale = 1./255,\n",
    "            validation_split=0.20\n",
    "        )\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                 horizontal_flip=True,\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "        else:\n",
    "            train_datagenerator = valid_datagenerator\n",
    "\n",
    "        self.train_generator = train_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"training\",\n",
    "            shuffle=True,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def cnn_train(self):\n",
    "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
    "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
    "\n",
    "        self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.params_epochs,\n",
    "            steps_per_epoch=self.steps_per_epoch,\n",
    "            validation_steps=self.validation_steps,\n",
    "            validation_data=self.valid_generator\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )\n",
    "\n",
    "  \n",
    "    def transaction_model_train(self):\n",
    "        Train_data=pd.read_csv(os.path.join(self.config.transaction_dir,'transaction_train.csv'))\n",
    "        Test_data=pd.read_csv(os.path.join(self.config.transaction_dir,'transaction_test.csv'))\n",
    "\n",
    "        try:\n",
    "            X_train=Train_data.drop(columns=['isFraud','Unnamed: 0'])\n",
    "            y_train=Train_data['isFraud']\n",
    "            X_test=Test_data.drop(columns=['isFraud','Unnamed: 0'])\n",
    "            y_test=Test_data['isFraud']\n",
    "            models={\n",
    "                'RandomForest':RandomForestClassifier(),\n",
    "                'LogisticRegression':LogisticRegression(),\n",
    "                'KNeighborsClassifier':KNeighborsClassifier(),\n",
    "                'GradientBoostingClassifier':GradientBoostingClassifier(),\n",
    "                'SVC':SVC(),\n",
    "                'XGBClassifier':XGBClassifier()\n",
    "            }\n",
    "            model_report:dict=evaluate_model_transaction(X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,models=models)\n",
    "            best_model_score=max(sorted(model_report.values()))\n",
    "            best_model_name=list(model_report.keys())[\n",
    "                list(model_report.values()).index(best_model_score)\n",
    "            ]\n",
    "            best_model=models[best_model_name]\n",
    "            print(best_model_score,best_model)\n",
    "            if best_model_score<0.9:\n",
    "                raise Exception('No Best model found')\n",
    "            logger.info(f'Best found model on both training and testing dataset for fraud')\n",
    "            save_object(self.config.transaction_model,best_model)\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    def creditscore_model_train(self):\n",
    "        Train_data=pd.read_csv(os.path.join(self.config.credit_score_dir,'credit_train.csv'))\n",
    "        Train_data.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "        Test_data=pd.read_csv(os.path.join(self.config.credit_score_dir,'credit_test.csv'))\n",
    "        Test_data.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "        try:\n",
    "            X_train=Train_data.drop(columns=['Credit Score'])\n",
    "            y_train=Train_data['Credit Score']\n",
    "            X_test=Test_data.drop(columns=['Credit Score'])\n",
    "            y_test=Test_data['Credit Score']\n",
    "            models=models={\n",
    "                'RandomForest':RandomForestClassifier(),\n",
    "                'LogisticRegression':LogisticRegression(),\n",
    "                'KNeighborsClassifier':KNeighborsClassifier(),\n",
    "                'GradientBoostingClassifier':GradientBoostingClassifier(),\n",
    "                'SVC':SVC(),\n",
    "                'XGBClassifier':XGBClassifier()\n",
    "            }\n",
    "            model_report:dict=evaluate_model_creditscore(X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,models=models)\n",
    "            best_model_score=max(sorted(model_report.values()))\n",
    "            best_model_name=list(model_report.keys())[\n",
    "                list(model_report.values()).index(best_model_score)\n",
    "            ]\n",
    "            best_model=models[best_model_name]\n",
    "            print(best_model_score,best_model)\n",
    "            if best_model_score<0.9:\n",
    "                raise Exception('No Best model found')\n",
    "            logger.info(f'Best found model on both training and testing dataset for credit')\n",
    "            save_object(self.config.credit_score_model,best_model)\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-23 22:28:29,775: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-07-23 22:28:29,784: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-07-23 22:28:29,789: INFO: common: created directory at: artifacts]\n",
      "[2024-07-23 22:28:29,791: INFO: common: created directory at: artifacts\\training]\n",
      "1.0 RandomForestClassifier()\n",
      "[2024-07-23 22:29:05,378: INFO: 3802236235: Best found model on both training and testing dataset for fraud]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bisht\\OneDrive\\Desktop\\Personal_project\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 GradientBoostingClassifier()\n",
      "[2024-07-23 22:29:07,451: INFO: 3802236235: Best found model on both training and testing dataset for credit]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config=ConfigurationManager()\n",
    "    training_config=config.get_training_config()\n",
    "    training=Training(config=training_config)\n",
    "    training.cnn_train()\n",
    "    training.transaction_model_train()\n",
    "    training.creditscore_model_train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3674432</td>\n",
       "      <td>18353.10</td>\n",
       "      <td>84926.31</td>\n",
       "      <td>66573.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2546147</td>\n",
       "      <td>242969.93</td>\n",
       "      <td>26966073.90</td>\n",
       "      <td>27209043.83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>219379</td>\n",
       "      <td>12396.64</td>\n",
       "      <td>180992.22</td>\n",
       "      <td>168595.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1981095</td>\n",
       "      <td>209743.85</td>\n",
       "      <td>4607817.81</td>\n",
       "      <td>4817561.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4507052</td>\n",
       "      <td>239116.87</td>\n",
       "      <td>5628300.97</td>\n",
       "      <td>5867417.84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063</th>\n",
       "      <td>6009612</td>\n",
       "      <td>5429153.98</td>\n",
       "      <td>5429153.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13064</th>\n",
       "      <td>6286329</td>\n",
       "      <td>48516.87</td>\n",
       "      <td>48516.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13065</th>\n",
       "      <td>6260944</td>\n",
       "      <td>277048.48</td>\n",
       "      <td>277048.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13066</th>\n",
       "      <td>5963369</td>\n",
       "      <td>36210.65</td>\n",
       "      <td>311431.61</td>\n",
       "      <td>275220.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13067</th>\n",
       "      <td>4784096</td>\n",
       "      <td>9207.38</td>\n",
       "      <td>9207.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13068 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      amount  oldbalanceOrg  newbalanceOrig  isFraud\n",
       "0         3674432    18353.10       84926.31        66573.21        0\n",
       "1         2546147   242969.93    26966073.90     27209043.83        0\n",
       "2          219379    12396.64      180992.22       168595.58        0\n",
       "3         1981095   209743.85     4607817.81      4817561.65        0\n",
       "4         4507052   239116.87     5628300.97      5867417.84        0\n",
       "...           ...         ...            ...             ...      ...\n",
       "13063     6009612  5429153.98     5429153.98            0.00        1\n",
       "13064     6286329    48516.87       48516.87            0.00        1\n",
       "13065     6260944   277048.48      277048.48            0.00        1\n",
       "13066     5963369    36210.65      311431.61       275220.96        0\n",
       "13067     4784096     9207.38        9207.38            0.00        1\n",
       "\n",
       "[13068 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(r'C:\\Users\\bisht\\OneDrive\\Desktop\\Personal_project\\artifacts\\data_ingestion\\transaction_data\\transaction_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
